{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'd:\\DeepPavlov_NLP3\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install --q deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch<1.13.0,>=1.6.0 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from torch<1.13.0,>=1.6.0) (4.4.0)\n",
      "Requirement already satisfied: pytorch-crf==0.7.* in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: transformers<4.21.0,>=4.13.0 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (4.20.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from transformers<4.21.0,>=4.13.0) (6.0)\n",
      "Requirement already satisfied: requests in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from transformers<4.21.0,>=4.13.0) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from transformers<4.21.0,>=4.13.0) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from transformers<4.21.0,>=4.13.0) (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from transformers<4.21.0,>=4.13.0) (1.21.6)\n",
      "Requirement already satisfied: filelock in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from transformers<4.21.0,>=4.13.0) (3.7.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from transformers<4.21.0,>=4.13.0) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from transformers<4.21.0,>=4.13.0) (2022.10.31)\n",
      "Requirement already satisfied: importlib-metadata in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from transformers<4.21.0,>=4.13.0) (5.1.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from transformers<4.21.0,>=4.13.0) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers<4.21.0,>=4.13.0) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from packaging>=20.0->transformers<4.21.0,>=4.13.0) (3.0.9)\n",
      "Requirement already satisfied: colorama in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from tqdm>=4.27->transformers<4.21.0,>=4.13.0) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from importlib-metadata->transformers<4.21.0,>=4.13.0) (3.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from requests->transformers<4.21.0,>=4.13.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from requests->transformers<4.21.0,>=4.13.0) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from requests->transformers<4.21.0,>=4.13.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\deeppavlov_nlp3\\env\\lib\\site-packages (from requests->transformers<4.21.0,>=4.13.0) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'd:\\DeepPavlov_NLP3\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'd:\\DeepPavlov_NLP3\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'd:\\DeepPavlov_NLP3\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install entity_detection_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Middle East, Africa and parts of Asia'], [129], [1.0]]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "#fraza = \"The history of Russia dates back more than a thousand years, starting with the migration of the Eastern Slavs to the Eastern European plain.\"\n",
    "#quest = \"Which country's history is it about?\"\n",
    "\n",
    "fraza = \"A military conflict involving 38 States between two coalitions of states in Europe, the fighting of which has also spread to the Middle East, Africa and parts of Asia\"\n",
    "quest = \"Whose fighting has spread to?\"\n",
    "\n",
    "check_text = requests.post('https://cb2a-5-165-12-53.eu.ngrok.io/model',json={'context_raw':[fraza], 'question_raw':[quest]}) \n",
    "text = str(check_text.json())\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 03:16:56.781 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/v1/ner/ner_ontonotes_bert_torch_crf.tar.gz download because of matching hashes\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['middle east', 'africa', 'asia']],\n",
       " [[(0, 11), (13, 19), (33, 37)]],\n",
       " [[[0, 1], [3], [7]]],\n",
       " [['LOC', 'LOC', 'LOC']],\n",
       " [[(0, 38)]],\n",
       " [['Middle East, Africa and parts of Asia.']],\n",
       " [[0.9952, 0.9931, 0.9929]]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deeppavlov import configs, build_model \n",
    "\n",
    "entity_extraction = build_model(configs.entity_extraction.entity_detection_en, download=True)\n",
    "\n",
    "# костыль начало (редактируем переменную для ввода в нейронку)\n",
    "\n",
    "text2 = text.replace(\"']\", \".\") \n",
    "text3 = text2.replace(\"[['\", \"\") \n",
    "#print(text)\n",
    "#print(text2)\n",
    "#print(text3)\n",
    "result_str = \"\" \n",
    "   \n",
    "for i in range(0, len(text3)): \n",
    "    if i < text3.find(\", [\"): \n",
    "        result_str = result_str + text3[i] \n",
    "#print(result_str)\n",
    "\n",
    "# костыль конец\n",
    "\n",
    "entity_extraction([result_str])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a718e9b7618fc4e990d906c2fb4081bcbe31f6872660828fbedcc78e90228feb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
